name: CPJ Lifecycle

on:
  workflow_dispatch:
    inputs:

      labName:
        description: The name of the lab (defaults to mva)
        required: false

      labNumberParticipants:
        description: The number of participants in the lab (defaults to 20)
        required: false

      nodeCount:
        description: The number of nodes to create (defaults to 3)
        required: false

      choice:
        required: true
        type: choice
        description: The stages to run (defaults to provision)
        options:
          - "provision"
          - "destroy"

      destroy:
        description: Destroy the lab? (defaults to false)
        type: boolean
        required: false

env:
  TF_VAR_labname: ${{ github.event.inputs.labName || 'mva' }}
  TF_VAR_labNumberParticipants: ${{ github.event.inputs.labNumberParticipants || '20' }}
  TF_VAR_nodecount: ${{ github.event.inputs.nodeCount || '3'}}

  TF_VAR_vmSizeAks: 'Standard_E8_v3'
  TF_VAR_rsgcommon: 'cloudacademy-common'
  TF_VAR_location: 'westeurope'
  TF_VAR_sshUserPw: 'CPJSchulung2022'
  
  TF_VAR_ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
  TF_VAR_ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
  TF_VAR_ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
  TF_VAR_ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
  TF_VAR_STATE_BLOBACCESSKEY: ${{ secrets.STATE_BLOBACCESSKEY }}
  TF_VAR_STATE_SAACCOUNTNAME: 'cloudacademyiacstate'

  # provision hosting
  hugoVersion: '0.76.1'
  ZIPPASS: 'cpjsecretpassword'

  # configure Participant-Pods
  AKSNAME: ${{ github.event.inputs.labName || 'mva' }}aks'
  TF_VAR_participantPodName: 'participant-pod-statefulset'
  TF_VAR_participantPodLabel: 'participant-pod'
  TF_VAR_participantPodNamespaceName: 'user'
  TF_VAR_participantPodDockerUser: 'novatec'

jobs:
  terraform:

    runs-on: ubuntu-latest

    # env:
      #TF_VAR_labname: ${{ github.event.inputs.labName || 'mva' }}
      # TF_VAR_labNumberParticipants: ${{ github.event.inputs.labNumberParticipants || '20' }}
      # TF_VAR_nodecount: ${{ github.event.inputs.nodeCount || '3'}}

      # TF_VAR_vmSizeAks: 'Standard_E8_v3'
      # TF_VAR_rsgcommon: 'cloudacademy-common'
      # TF_VAR_location: 'westeurope'
      # TF_VAR_sshUserPw: 'CPJSchulung2022'
      
      # TF_VAR_ARM_SUBSCRIPTION_ID: ${{ secrets.ARM_SUBSCRIPTION_ID }}
      # TF_VAR_ARM_CLIENT_ID: ${{ secrets.ARM_CLIENT_ID }}
      # TF_VAR_ARM_CLIENT_SECRET: ${{ secrets.ARM_CLIENT_SECRET }}
      # TF_VAR_ARM_TENANT_ID: ${{ secrets.ARM_TENANT_ID }}
      # TF_VAR_STATE_BLOBACCESSKEY: ${{ secrets.STATE_BLOBACCESSKEY }}
      # TF_VAR_STATE_SAACCOUNTNAME: 'cloudacademyiacstate'

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Terraform plan
        if: "${{ github.event.inputs.choice == 'provision' && github.event.inputs.destroy == 'false' }}"
        env:
          TF_ACTION: 'plan'
        run: |
          #!/bin/bash
          set -xe

          docker run \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
                init \
                    -backend-config="key=${{ env.TF_VAR_labname }}-components.tfstate" \
                    -backend-config="access_key=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
                    -backend-config=storage_account_name="${{ env.TF_VAR_STATE_SAACCOUNTNAME }}"
          
          docker run \
            -e "ARM_SUBSCRIPTION_ID=${{ env.TF_VAR_ARM_SUBSCRIPTION_ID }}" \
            -e "ARM_CLIENT_ID=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "ARM_CLIENT_SECRET=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "ARM_TENANT_ID=${{ env.TF_VAR_ARM_TENANT_ID }}" \
            -e "STATE_BLOBACCESSKEY=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
            -e "TF_VAR_labname=${{ env.TF_VAR_labname }}" \
            -e "TF_VAR_location=${{ env.TF_VAR_location }}" \
            -e "TF_VAR_labNumberParticipants=${{ env.TF_VAR_labNumberParticipants }}" \
            -e "TF_VAR_vmSizeAks=${{ env.TF_VAR_vmSizeAks }}" \
            -e "TF_VAR_nodecount=${{ env.TF_VAR_nodecount }}" \
            -e "TF_VAR_clientid=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "TF_VAR_clientsecret=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "TF_VAR_rsgcommon=${{ env.TF_VAR_rsgcommon }}" \
            -e "TF_VAR_sshUserPw=${{ env.TF_VAR_sshUserPw }}" \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
              ${{ env.TF_ACTION }} \
        working-directory: 'infrastructureAsCode'

      - name: Terraform apply
        if: "${{ github.event.inputs.choice == 'provision' && github.event.inputs.destroy == 'false' }}"
        env:
          TF_ACTION: 'apply'
          TF_OPTIONS: '--auto-approve'
        run: |
          #!/bin/bash
          set -xe

          docker run \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
                init \
                    -backend-config="key=${{ env.TF_VAR_labname }}-components.tfstate" \
                    -backend-config="access_key=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
                    -backend-config=storage_account_name="${{ env.TF_VAR_STATE_SAACCOUNTNAME }}"
          
          docker run \
            -e "ARM_SUBSCRIPTION_ID=${{ env.TF_VAR_ARM_SUBSCRIPTION_ID }}" \
            -e "ARM_CLIENT_ID=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "ARM_CLIENT_SECRET=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "ARM_TENANT_ID=${{ env.TF_VAR_ARM_TENANT_ID }}" \
            -e "STATE_BLOBACCESSKEY=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
            -e "TF_VAR_labname=${{ env.TF_VAR_labname }}" \
            -e "TF_VAR_location=${{ env.TF_VAR_location }}" \
            -e "TF_VAR_labNumberParticipants=${{ env.TF_VAR_labNumberParticipants }}" \
            -e "TF_VAR_vmSizeAks=${{ env.TF_VAR_vmSizeAks }}" \
            -e "TF_VAR_nodecount=${{ env.TF_VAR_nodecount }}" \
            -e "TF_VAR_clientid=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "TF_VAR_clientsecret=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "TF_VAR_rsgcommon=${{ env.TF_VAR_rsgcommon }}" \
            -e "TF_VAR_sshUserPw=${{ env.TF_VAR_sshUserPw }}" \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
              ${{ env.TF_ACTION }} \
              ${{ env.TF_OPTIONS }}
        working-directory: 'infrastructureAsCode'

      - name: Terraform destroy
        if: "${{ github.event.inputs.choice == 'destroy' && github.event.inputs.destroy == 'true' }}"
        env:
          TF_ACTION: 'destroy'
          TF_OPTIONS: '--auto-approve'
        run: |
          #!/bin/bash
          set -xe

          docker run \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
                init \
                    -backend-config="key=${{ env.TF_VAR_labname }}-components.tfstate" \
                    -backend-config="access_key=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
                    -backend-config=storage_account_name="${{ env.TF_VAR_STATE_SAACCOUNTNAME }}"
          
          docker run \
            -e "ARM_SUBSCRIPTION_ID=${{ env.TF_VAR_ARM_SUBSCRIPTION_ID }}" \
            -e "ARM_CLIENT_ID=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "ARM_CLIENT_SECRET=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "ARM_TENANT_ID=${{ env.TF_VAR_ARM_TENANT_ID }}" \
            -e "STATE_BLOBACCESSKEY=${{ env.TF_VAR_STATE_BLOBACCESSKEY }}" \
            -e "TF_VAR_labname=${{ env.TF_VAR_labname }}" \
            -e "TF_VAR_location=${{ env.TF_VAR_location }}" \
            -e "TF_VAR_labNumberParticipants=${{ env.TF_VAR_labNumberParticipants }}" \
            -e "TF_VAR_vmSizeAks=${{ env.TF_VAR_vmSizeAks }}" \
            -e "TF_VAR_nodecount=${{ env.TF_VAR_nodecount }}" \
            -e "TF_VAR_clientid=${{ env.TF_VAR_ARM_CLIENT_ID }}" \
            -e "TF_VAR_clientsecret=${{ env.TF_VAR_ARM_CLIENT_SECRET }}" \
            -e "TF_VAR_rsgcommon=${{ env.TF_VAR_rsgcommon }}" \
            -e "TF_VAR_sshUserPw=${{ env.TF_VAR_sshUserPw }}" \
            -v "$(pwd)"/:/workspace \
            -w /workspace \
            hashicorp/terraform:latest \
              ${{ env.TF_ACTION }} \
              ${{ env.TF_OPTIONS }}
        working-directory: 'infrastructureAsCode'

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Azure CLI script
        uses: azure/CLI@v1
        env: 
          blob: '${{ env.TF_VAR_labname }}-components.tfstate'
        with:
          azcliversion: 2.30.0
          inlineScript: |
            az storage blob delete --delete-snapshots include --account-name cloudacademyiacstate --container-name terraformstate --name ${blob} 

  hosting:
  

    needs: terraform

    runs-on: ubuntu-latest

    if: "${{ github.event.inputs.choice == 'provision' && github.event.inputs.destroy == 'false' }}"

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Download Hugo
        run: |
          wget -c 'https://github.com/gohugoio/hugo/releases/download/v${{ env.hugoVersion }}/hugo_extended_${{ env.hugoVersion }}_Linux-64bit.deb'
      - name: Install Hugo
        run: |
          sudo dpkg -i hugo_extended_${{ env.hugoVersion }}_Linux-64bit.deb

      - name: Azure Login
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Checkout excercises
        uses: actions/checkout@master
        with:
          repository: NovatecConsulting/technologyconsulting-cpj-excercises
          ref: 'main'
          token: ${{ secrets.GH_PAT }}
          path: './hugo'

      - name: Hugo

        run: |
          #!/bin/bash
          set -xe

          # now part of terraform script
          # az extension add --name storage-preview
          # az storage blob service-properties update \
          #   --account-name "${{ env.TF_VAR_labname }}materials" \
          #   --static-website \
          #   --404-document 404.html \
          #   --index-document index.html

          cd ./hugo
        
          pwd
          echo 'add Pod-Service data into hugofiles'

          echo "<h2>IP Addressen</h2>" >> content/_index.md

          AKSNAME="${{ env.TF_VAR_labname }}aks"

          az aks get-credentials -g ${{ env.TF_VAR_labname }} -n $AKSNAME

          echo "Get Participant Pods Service IPs"

          kubectl get svc

          printf "<h3>Webssh-Server Loadbalancer IP </h3>" >>  content/_index.md

          printf "<p>" >>  content/_index.md
          kubectl describe svc webssh-server | grep Ingress >>  content/_index.md
          printf "</p>" >>  content/_index.md
          printf "<br/>" >>  content/_index.md

          printf "<h3>Pod-Service Loadbalancer IPs </h3>" >>  content/_index.md

          for ((i = i; i<$TF_VAR_labNumberParticipants; i++)); do
            printf "<h5>Pod $i Service ClusterIP: </h5>" >>  content/_index.md

            printf "<p>" >>  content/_index.md
            kubectl describe svc "participant-pod-$i-service" | grep Ingress >>  content/_index.md
            printf "</p>" >>  content/_index.md

            printf "<p>" >>  content/_index.md
            kubectl describe svc "participant-pod-$i-service" | grep IPs >>  content/_index.md
            printf "</p>" >>  content/_index.md
            printf "<br/>" >>  content/_index.md
          done


          echo 'creating hugo static page'
          mkdir themes && cd themes && git clone https://github.com/matcornic/hugo-theme-learn.git && cd ..
          # TC-380: update clipboards.js to avoid jumping in page on copy-to-clipboard when focus was lost
          curl -sSL https://raw.githubusercontent.com/zenorocha/clipboard.js/master/dist/clipboard.min.js > themes/hugo-theme-learn/static/js/clipboard.min.js

          cp config.toml localZIPgenConfig.toml

          sed -i 's/relativeURLs = "false"/relativeURLs = "true"/g' localZIPgenConfig.toml
          sed -i 's/uglyURLs = "false"/uglyURLs = "true"/g' localZIPgenConfig.toml
          sed -i 's/publishDir = "public"/publishDir = "CPJ"/g' localZIPgenConfig.toml
          sed -i 's/baseURL = "\/"/baseURL = ""/g' localZIPgenConfig.toml
          sed -i 's/HUGO\_BASEURL = "https\:\/\/cloudacademyhugo.z6.web.core.windows.net\/"/HUGO_BASEURL = ""/g' localZIPgenConfig.toml

          cat localZIPgenConfig.toml
          echo ""
          echo "create zip folder"

          sudo hugo --config localZIPgenConfig.toml
          ls CPJ/

          echo "zip pass var is:"
          echo ${{ env.ZIPPASS }}
          zip -rP ${{ env.ZIPPASS }} cloud_platform_journey-materials.zip CPJ/
          cp cloud_platform_journey-materials.zip content/_index.files/
          sudo hugo --log -v
          ls public/

          az storage blob upload-batch -d \$web -s ./public --account-name "${{ env.TF_VAR_labname }}materials"

  configure:
    needs: terraform
    runs-on: ubuntu-latest
    if: "${{ github.event.inputs.choice == 'provision' && github.event.inputs.destroy == 'false' }}"

    steps:
    - name: executing shell script
      run: |
        #!/bin/bash
        set -xe

        AKSNAME                             = "${{ env.TF_VAR_labname }}aks"
        TF_VAR_labname                      = "${{ env.TF_VAR_labname }}"
        TF_VAR_sshUserPw                    = "${{ env.TF_VAR_sshUserPw }}"
        TF_VAR_labNumberParticipants        = "${{ env.TF_VAR_labNumberParticipants }}"
        TF_VAR_participantPodName           = "${{ env.TF_VAR_participantPodName }}"
        TF_VAR_participantPodLabel          = "${{ env.TF_VAR_participantPodLabel }}"
        TF_VAR_participantPodNamespaceName  = "${{ env.TF_VAR_participantPodNamespaceName }}"
        TF_VAR_participantPodDockerUser     = "${{ env.TF_VAR_participantPodDockerUser }}"




        az aks get-credentials -g ${TF_VAR_labname} -n $AKSNAME

        echo "Configure Kubectl in Participant Pods"

        kubectl get pods

        echo "Testing Sysbox-Daemonset"
        until kubectl get daemonsets sysbox-deploy-k8s -n kube-system -o jsonpath="{.status.numberReady}" | grep -v --silent 0; do
          kubectl describe daemonsets sysbox-deploy-k8s -n kube-system
          kubectl get daemonsets sysbox-deploy-k8s -n kube-system

          date
          echo "No Worker-Node with Sysbox-Daemonset ready. Waiting 30s"
          sleep 30
        done
        echo "Testing Sysbox-Daemonset Success"

        echo "Testing Participant-Pod"
        until kubectl get statefulSets $TF_VAR_participantPodName -o jsonpath="{.status.readyReplicas}" | grep -q $TF_VAR_labNumberParticipants; do
          kubectl get statefulSets $TF_VAR_participantPodName -o jsonpath="{.status.readyReplicas}" | grep -v 0
          kubectl get pods

          date
          echo "Not all Participant-Pod are ready. Waiting 10s"
          sleep 10
        done
        echo "Testing Participant-Pod Success"

        echo "Configure Participant-Pod"

        USER_NOVATEC_DIR=home/$TF_VAR_participantPodDockerUser
        USER_ROOT_DIR=/root

        CONTEXT="$(kubectl config current-context)"
        printf "$CONTEXT \n"

        CLUSTER_NAME="$(kubectl config get-contexts "$CONTEXT" | awk '{print $3}' | tail -n 1)"
        printf "$CLUSTER_NAME \n"

        ENDPOINT="$(kubectl config view -o jsonpath="{.clusters[?(@.name == \"${CLUSTER_NAME}\")].cluster.server}")"
        printf "$ENDPOINT \n"

        for ((c = 0; c < $TF_VAR_labNumberParticipants; c++)); do
          echo "Iteration: $c"

          printf "\nInnerhalb des Pods '$TF_VAR_participantPodName-$c' das Kubernetes Cluster konfigurieren, sodass der Pod Ã¼ber kubectl darauf zugreifen kann... \n"

          SERVICE_ACCOUNT_NAME=$TF_VAR_participantPodNamespaceName-$c-sa
          printf "$SERVICE_ACCOUNT_NAME \n"

          NAMESPACE=$TF_VAR_participantPodNamespaceName-$c
          printf "$NAMESPACE \n"

          SECRET_NAME="$(kubectl get sa $SERVICE_ACCOUNT_NAME --namespace=$NAMESPACE -o json | jq -r .secrets[].name)"
          printf "$SECRET_NAME \n"

          kubectl get secret --namespace=$NAMESPACE $SECRET_NAME -o json | jq -r '.data["ca.crt"]' | base64 -di > participant-pod/ca$c.crt

          USER_TOKEN="$(kubectl get secret --namespace $NAMESPACE $SECRET_NAME -o json | jq -r '.data["token"]' | base64 -di)"
          printf "$USER_TOKEN \n"


          kubectl cp participant-pod/ca$c.crt $TF_VAR_participantPodName-$c:$USER_ROOT_DIR

          rm participant-pod/ca$c.crt

          kubectl cp participant-pod/example-deployments $TF_VAR_participantPodName-$c:$USER_ROOT_DIR
          kubectl cp participant-pod/configs/.bashrc $TF_VAR_participantPodName-$c:$USER_ROOT_DIR


          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(kubectl config set-cluster "${CLUSTER_NAME}" --server="${ENDPOINT}" --certificate-authority="${USER_ROOT_DIR}/ca${c}".crt --embed-certs=true)"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(kubectl config set-credentials "${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}" --token="${USER_TOKEN}")"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(kubectl config set-context "${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}" --cluster="${CLUSTER_NAME}" --user="${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}" --namespace="${NAMESPACE}")"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(kubectl config use-context "${SERVICE_ACCOUNT_NAME}-${NAMESPACE}-${CLUSTER_NAME}")"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(echo  $'\nKUBECONFIG=${USER_ROOT_DIR}/.kube/config' >> "${USER_ROOT_DIR}"/.bashrc)"

          echo "Configure Novatec-User \n"

          kubectl cp participant-pod/example-deployments $TF_VAR_participantPodName-$c:$USER_NOVATEC_DIR
          kubectl cp participant-pod/configs/.bash_profile $TF_VAR_participantPodName-$c:$USER_NOVATEC_DIR
          kubectl cp participant-pod/configs/.bashrc $TF_VAR_participantPodName-$c:$USER_NOVATEC_DIR


          # Change PW of Novatec-User
          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(echo "${TF_VAR_participantPodDockerUser}:${TF_VAR_sshUserPw}" | chpasswd)"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(mkdir -p ${USER_NOVATEC_DIR}/.kube)"
          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(cp -r "${USER_ROOT_DIR}"/.kube/config "${USER_NOVATEC_DIR}"/.kube)"
          # kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(chown -R $TF_VAR_participantPodDockerUser "${USER_NOVATEC_DIR}"/.kube/)"

          kubectl exec -it $TF_VAR_participantPodName-$c -- bash -c "(echo  $'\nKUBECONFIG=${USER_NOVATEC_DIR}/.kube/config' >> "${USER_NOVATEC_DIR}/.bashrc")"

        done